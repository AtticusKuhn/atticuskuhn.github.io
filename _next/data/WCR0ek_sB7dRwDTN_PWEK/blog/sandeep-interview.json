{"pageProps":{"blog":{"content":"\nSandeep Srinivasan is a veteran of the machine learning industry. While most have gravitated towards it since the hype of the late 2000s, Srinivasan claims he has been “interested in machine learning since the 1990s,” almost noachian in this quickly evolving field. Today, I sat down with Srinivasan in order to glean what insights he has after pioneering this industry for 30 years. \n\nI am struck by Srinivasan’s positive attitude. He himself concurs, saying its necessary to be “a lifelong learner” to succeed in this field. Even with his experience, he is “still taking courses” to learn new skills and improve himself. His optimism extends further, however. When describing how he first got into machine learning, Srinivasan said a professor was too embarrassed that no one signed up for his course in machine learning, so he paid Srinivasan $10 an hour to be the only attendant. Despite being happenstance, Srinivasan tells the story with a smile as if it is a good joke. He brings this sense of optimism to his work, summarizing that the “best part of [his] job” is to meet bright 20-year-olds who have a “beginner’s mindset” and are eager to learn. \n\nFinding these bright 20-year-olds is becoming increasingly difficult for Srinivasan, unfortunately. In this white-hot field, he must muscle his way through the likes of “Google, Facebook, Amazon, and Apple.” Due to this drive for talent, Srinivasan complains that “the hardest part” of his job is hiring for his small machine learning startup.\n\nDespite his recruiting woes, Srinivasan claims he is not deterred about founding a small machine learning startup. He says the experience has been rewarding for him. When speaking on the advantages of founding a startup, he says he gets to “eat [his] own dog food,” in the sense that he is excited to try out all the products as a consumer that he is inventing. He emphasize that a founder must act as the first customer of a product, because if the founder doesn’t believe in the product, then neither will the clients. \n\nThe main area where Srinivasan eagerly gets to try out his new inventions is with his products aiming to “simplify machine learning.” He uses his own online dashboard to set up machine learning models in a few clicks, and soon he hopes others can do the same. His mission is to “democratize machine learning for multiple applications.”  In the future, Srinivasan imagines that doctors or other domain experts could create machine learning models without coding and without technical knowledge. \n\t\nDoctors are not the only profession Srinivasan predicts machine learning will impact. He thinks that many “repetitive tasks” such as “data entry” for taxes will disappear. In addition, manual tasks, such as image labeling will be automated away by machine learning.\n\nOverall, I am very impressed with Srinivasan’s accomplishments. He certainly has the air of someone well-informed on the industry, and he was able to use his knowledge to give me personal advice for the job market (“learn statistics”). Given how he effuses knowledge in every aspect of machine learning, I would not be surprised if his startup goes far. This experience was very informative for me, and I see myself possibly having a career in machine learning. I suggest to the reader to conduct a similar informational interview, in the hopes that one could learn about an intriguing field from a personality. \n\n\n \n","date":"Feb 27, 2022","tags":["machine learning"," interview"," coding"],"title":"Interview with Machine Learning Expert","slug":"sandeep-interview","description":"After his 30 years in the field, machine learning engineer Sandeep Srinivasan offers advice on how to tackle this complex career.","image":"/images/sandeep.jpg"},"reccomendedBlog":[{"content":"\nIn recent years, we've seen a lot of hype around machine learning. From [alpha go](https://deepmind.com/research/case-studies/alphago-the-story-so-far), which beat world-champion go\nplayers, to [GPT-3](https://en.wikipedia.org/wiki/GPT-3), the constant news buzz\nwould make one think we are around the corner from [AI Dominance](https://en.wikipedia.org/wiki/Technological_singularity). But I claim today that most of AI is just hype, with no\nreal substance behind it. Of course time will tell the true use of AI. In fact, most\ntimes teams eagerly throw a [neural net](https://en.wikipedia.org/wiki/Neural_network) at\na problem, they are really looking for a symbolic manipulation tool like [prolog](https://en.wikipedia.org/wiki/Prolog).\n\n# Black Boxes\n\nThe first drawback of machine learning is they are incomprehensible. If a machine learning model\nmakes a mistake, how will you figure out what went wrong? There is no real way of knowing. Sure,\nyou can look at the internal state of the model, but what does that really tell you?\nModels today are getting so large that it is impossible to hold a single one in your\nbrain. GPT-3 has [175 billion parameters](https://www.springboard.com/blog/data-science/machine-learning-gpt-3-open-ai/#:~:text=The%20largest%20version%20GPT%2D3,and%203.2%20M%20batch%20size.&text=Shown%20in%20the%20figure%20above,that%20it%20is%20quite%20larger.)\nparameters. What if it makes a mistake? Will some engineer have to go through all\n175 billion parameters just to find it? I think the true solution is [declarative](https://en.wikipedia.org/wiki/Declarative_programming) software\nthat simply states rules or definitions. That code is easier to debug and understand for\nnew users. In essence, we can only look at machine learning as a black box.\n\n# Changing Requirements\n\nOften in software engineering, projects are subject to [changing requirements](https://rebelsguidetopm.com/help-the-requirements-keep-changing-and-i-cant-nail-them-down-part-2/).\nWhat happens when this is done to a machine learning model? In short, I don't\nsee how a machine learning model trained for one task can be fixed to work on\na slightly different task. It would require a whole new retraining of the model\nevery time you want to make a change. Google even spoke about this issue in their\npaper [Machine Learning:\nThe High-Interest Credit Card of Technical Debt](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf). In our ever-changing world, you must truly\nconsider if you want to use a technology that requires so much effort even to change\nits purpose slightly.\n\n# Declarative Programming: is it Nirvana?\n\nI am a huge fan of declarative programming, whether from the [Wolfram Language](https://en.wikipedia.org/wiki/Wolfram_Language) or from [Prolog](https://en.wikipedia.org/wiki/Prolog).\nIn such a style, the programmer simply states the rules of the system formally, and\nthe language takes care of implementation concerns. This approach is easy to understand\nbecause it is just the rules of the system. In addition, it is easy to understand\nthe behavoir of a program: just follow which rules it applied.  If you have never\nheard of prolog, I strongly encourage you to check it out. It is unlike any other\nprogramming language, not part of the C or ALGOL lineage. It will rethink the way\nthat you understand the purpose of computers, [so try it out](https://swish.swi-prolog.org/).","date":"January 27, 2022","tags":["machine learning"," ml"," AI"],"title":"Machine Learning is overrated","slug":"machine-learning-overrated","description":"I don't understand the hype around machine learning","image":"/images/Blog-Images-Forget-Machine-Learning-Humans-Still-Have-a-Lot-to-Learn-Part-II.jpg"},{"content":"\n\nSince haskell is a list-based language, there are many ways to work with lists. This article details some of the most interesting ways to multiply each number in a list by 5. \n1. The Imperative way\n```haskell,\nmain:: IO()\nmain = do\n  mutable <- M.replicate 256 1\n  forM_ ([1..256] z->\n    modify mutable (x->x*5) z\n   )\n```\n2. The boring way\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = map (\\x->x*5) xs\n```\n3. currying\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList = map (*5) \n```\n4. monad\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs =  xs >>= (\\x -> [x*5])\n```\n5. short functor\n```haskell,\nm=(<$>)(*5)\n```\n6. List comprehension\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = [x*5 | x <- xs]\n```\n\n\n7. Do notation\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = do\n    x <- xs\n    return $ x*5\n```\n\n8. Functor\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = fmap (\\x -> x*5) xs\n```\n9. Applicative\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs =  pure (\\x->x*5) <*> xs\n```\n10. Recursion\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList [] = []\nmultiplyList (x:xs) = (x*5) : multiplyList xs\n```\n\n\n\n\n\n","date":"May 2, 2021","tags":["haskell"," list"," map"," functor"],"title":"10 ways to map a list in haskell","slug":"10-ways-to-map-a-list","description":"Haskell is such a cool language","image":"/images/techs/haskell.png"},{"content":"\n\n# What is Undecidability\n\nLike Icarus flying too close to the sun it seems that every mathematical system\nwill eventually be drawn towards the black hole of undecidability. Decidability\nbasically means there is an algorithm to answer a question. [Adding Numbers](https://lisbdnet.com/what-is-standard-algorithm-addition/#:~:text=standard%20algorithm%20addition%3F-,The%20standard%20algorithm%20for%20addition%20has%20three%20simple%20rules%3A,3%3A%20Regroup%2C%20if%20necessary) is decidable but [finding the shortest path](https://en.wikipedia.org/wiki/Travelling_salesman_problem) is not. In general I have noticed a pattern in\nall systems of rules. The system starts off simple. Then, as more use cases pile up, more\nrules and properties are added until suddenly, the system is undecidable. What happend here?\nI will start with a few examples\n\n# Typing Systems for Programming Languages\n\nI first encountered this problem in the type system of programming languages, or basically\nan algorithm that says `5` is an integer or `[1,2,3]` is a list of integers. You may think this problem is easy, and indeed the way I have just phrased it is decidable by [Algorithm W](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system#Algorithm_W). A type system is very useful,\nbut people have encountered corner cases, such as depenedent types or linear types, and they\ntry to extend the type system. For example, if you are trying to figure out the type of \n[C](https://en.wikipedia.org/wiki/The_C_Programming_Language)'s [printf](https://en.wikipedia.org/wiki/Printf_format_string), you might realise that the type of the second\nargument depends on the type of the first argument.\n\n```c\nprintf(\"%f %s\", 1.2, \"hello\")\n```\nIf you want to encode this information into the type system, then you have just discovered\ndependent types, where types depend on values. The problem of finding out if a dependently\ntyped program is valid is actually undecidable (as a subset of the [halting problem](https://en.wikipedia.org/wiki/Halting_problem)). One you say you want this, you have stepped out\nof the safety of decidable typing and you might now need to prove to the compiler\nusing a formal proof that a program typchecks, such as in languages such as [Idris](https://www.idris-lang.org/). A good documentation of this problem is on the website [typing is hard](https://3fx.ch/typing-is-hard.html).\n\nIn my view, the ideal type system of a programming language should be decidable. I don't want\nto have to write a proof that my progam is valid. The best type system for this is [Hindley-Milner](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system) which is about as far as you can creep before you plumet off the cliff of undeciability.\n\n# Presbuger Arithmetic\n\nAnother beautiful example of walking the tightrope of decidability is [Presburger Arithmetic](https://en.wikipedia.org/wiki/Presburger_arithmetic). Surprisingly, it is a formulation of arithmetic\nwhere every statement is decidable by a simple algorithm. For example, you can say \n`x+y > 10` and the Presburger algorithm will find all satisfying x and y. What is the catch?\nThere is no multiplication. Presbuger Arithmetic only has plus, equals, there exists, and for all.\nSo statements about prime factorization, for example, are impossible to state in Presburger Arithmetic. It seems that multiplcation is intricately linked with undecidability. And\nOnce we say we want multiplication, arithmetic no longer becomes decidable.\n\n# Undecidability is Interesting\n\nUnlike programmers, who would want decidabilty type systems, we mathematicians do **not**\nwant decidability in our systems. In truth, decidable systems are boring, and pose no\ninteresting mathematical questions. Due to the well-established relationship between\nexpressiveness and decidability, once we make a system expressive enough to pose\ninteresting questions, it becomes undecidable. Furthermore, in decidable systems,\ntruth is simply a matter of computation. If you want to check if a statement is \ntrue, just run a computer to check it. Mathematics in decidable systems loses\nall its beauty and elegance of unconventional proofs.  So maybe undeciability isn't so bad.\n\n# Walking off the Cliff\n\nWhat can you take away from this? Well let's say you're designing a programming tool like\na configuration language or a macro system. Users might demand more and more features, until,\nunwittingly, your simple little tool becomes undecidable. This happened to C++ templates,\nwhere now they are [turing complete](https://stackoverflow.com/questions/189172/c-templates-turing-complete) (or in other words undecidable). So my advice is to\nkeep in mind the original goal of your project and be aware of any features that\nmight cause you to wander from the island of safety that is decidability. \n\n\n","date":"April 7, 2022","tags":["automata"," decidability"," presbuger arithmetic"," type system"],"title":"The Decidability Tradeoff","slug":"decidability-tradeoff","description":"There is a fine line between power and decidability","image":"/images/automata.jpeg"}]},"__N_SSG":true}