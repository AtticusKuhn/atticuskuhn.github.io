{"pageProps":{"blog":{"content":"\n\n\nI recently looked at [A Talk by Bob Martin](https://www.youtube.com/watch?v=P2yr-3F6PQo) in which\nhe says that we've \"basically discovered all the programming paradigms\". He says this due to his\nview that programming paradigms are just restrictions on what programmers can do, but I disagree.\nMy view is that **a good programming language is the minimal amount needed to add to a model\nof computation**. I will explain what I mean.\n\n## Models of Computation\nAccording to Wikipedia, a [Model of Computation](https://en.wikipedia.org/wiki/Model_of_computation) is\n\"a model which describes how an output of a mathematical function is computed given an input\".\nThere are a list of models of computation on the page, which include\n- Post machines\n- Pushdown automata\n- Register machines\n- Random-access machines\n- Turing machines\n- Decision tree model\n- Abstract rewriting systems\n- Combinatory logic\n- General recursive functions\n- Lambda calculus\n- Actor model\n- Cellular automaton\n- Interaction nets\n- Kahn process networks\n- Logic gates and digital circuits\n- Petri nets\n- Synchronous Data Flow\n\nAs you can see, there are many models of computation.\n## Minimal Addition\nWhat do I mean by \"minimal additon\". Well, a model of computation only describes mathematical functions, which are pure. We would like our programs to be able to interact with the outside world. This means\nsome abilities must be added to a model of computation in order to allow interaction. The gold\nstandard for this is [Haskell](https://en.wikipedia.org/wiki/Haskell), with its monadic model of computation. In a good language, effects should be modelled using some kind of language construct, such\nas Haskell's monads, but I think the construct will vary for each model of computation.\n\n## Examples of Well-Loved Languages\n\nI will show how the best-designed languages today are simply the minimal additions to already good\nmodels of computation.\n\n\n| Model of Computation| Language|\n|--------------------|----------|\n| Untyped Lambda Calculus | Lisp|\n| Typed Lambda Calculus | Haskell|\n| Predicate Logic | Prolog |\n| Rewriting System | Wolfram |\n| Actor Model | Smalltalk |\n| Interaction Nets | [Kind2](https://github.com/Kindelia/Kind2) |\n| Combinatory Logic | APL | \n\nHopefully you see that all the languages on the right column are widely admired for being well-designed.\nAnd what unifies them all? They are all strictly based on a model of computation.\n\nLet us discuss the example of Lisp. Lisp is the [minimal wrapper](https://news.ycombinator.com/item?id=29950782) on top of the untyped lambda calculus. It does not include any features\nbeyound unleashing the inherent power of the lambda calculus. This is the main difference\nbetween Smalltalk and Java. Both are based on the [Actor Model](https://en.wikipedia.org/wiki/Actor_model)\nbut Smalltalk sticks truthfully to its model of computation, while Java confusedly\nborrows concepts from other languages.\n\n## Turing Completeness\nDue to Turing Completeness, we can say that all models of computation are equally expressive.\nSo, it remains to be decided what model we should use. I think we should first choose a model\nthat is the best for our needs.\n\n## Good Models of Computation\nGiven all these models of computation, which should we chose as a basis for our languages?\nI think it comes down to 2 critera:\n- being simple\n- having nice properties\n\nFor the first point, I think the model should be very simple. I think the [SK Calculus](https://en.wikipedia.org/wiki/SKI_combinator_calculus) is very good in this regard, and it might be the simplest model\nof computation that I have ever seen. Turing Machines, although the most well-known example of\na model of computation, are actually very complex and hard to explain. \n\nFor the second point, I mean that the model has properties that make it easy to implement and\nfast to run on our given hardware. One model that is very promising is [Interaction Nets](https://en.wikipedia.org/wiki/Interaction_nets#Properties) because they have these properties\n\n- locality (only active pairs can be rewritten)\n- linearity (each interaction rule can be applied in constant time)\n- strong confluence \n\nThese properties would make an implementation very fast, so I encourage you to try writing\nan implementation.\n\n\n## Advice to Aspiring Language Designers\nIf you want to design a language, I have some advice for how to do it. The first step is to\nchoose a model of computation that has not yet been well-explored. For example, I would\nnot design a language based on lambda calculus because that space has already been perfected\nby Lisp and Haskell, and I would not design a langauge based on predicate logic because\nProlog already does a good job there. I would choose a model that has good properties (can\nbe executed quickly on hardware) and has not been explored by any other language. Right\nnow I think the field of Linear Logic doesn't have its own industry-strength programming\nlanguage. If you think you can design such a language, I would encourage you on.\n\n\n## Summary\nIn short, a programming language is nothing but an implentation of a model of computation.","date":"Oct 10, 2022","tags":["programming"," math"," computation"," lisp"],"title":"How to Create an Excellent Programming Lanugage","slug":"create-language","description":"I have come up with a method to design well-loved languages","image":"/images/lisp.png"},"reccomendedBlog":[{"content":"\n\nSince haskell is a list-based language, there are many ways to work with lists. This article details some of the most interesting ways to multiply each number in a list by 5. \n1. The Imperative way\n```haskell,\nmain:: IO()\nmain = do\n  mutable <- M.replicate 256 1\n  forM_ ([1..256] z->\n    modify mutable (x->x*5) z\n   )\n```\n2. The boring way\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = map (\\x->x*5) xs\n```\n3. currying\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList = map (*5) \n```\n4. monad\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs =  xs >>= (\\x -> [x*5])\n```\n5. short functor\n```haskell,\nm=(<$>)(*5)\n```\n6. List comprehension\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = [x*5 | x <- xs]\n```\n\n\n7. Do notation\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = do\n    x <- xs\n    return $ x*5\n```\n\n8. Functor\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs = fmap (\\x -> x*5) xs\n```\n9. Applicative\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList xs =  pure (\\x->x*5) <*> xs\n```\n10. Recursion\n```haskell,\nmultiplyList :: [Int] -> [Int]\nmultiplyList [] = []\nmultiplyList (x:xs) = (x*5) : multiplyList xs\n```\n\n\n\n\n\n","date":"May 2, 2021","tags":["haskell"," list"," map"," functor"],"title":"10 ways to map a list in haskell","slug":"10-ways-to-map-a-list","description":"Haskell is such a cool language","image":"/images/techs/haskell.png"},{"content":"\n\nI just recently got back from attending the [Ross Mathematics Program](https://rossprogram.org/) in Ohio and\nI would like to give a review. I came back from the airport giddy with excitement, and I wish that\nthe Ross Program could go for another week to distract me from school.\n\n## The Math\n\nOn the Ross Website, it makes it seem like you will do nothing but math for 6 weeks, and I can say that \nthe Ross Program is exactly as advertised. You will get 6 weeks of mathematics. The main curriculum in\nnumber theory was very interesting, and gave me a deeper appreciation of the integers. You may think\nthat proving that if a is divisible by b, then b < a might be a trivial task, but  at the Ross Program,\nwe go **FULL RIGOR**, meaning that every proposition must be directly from the axioms with minimal\ninference or hand waving (the student's response: \"full rigor leads to rigor mortis\"). All the problem\nsets have interesting problems that test your conceptions of numbers. \n\n## The Counsellors\nAll the counsellors at the Ross Program are excited to help you with math and discuss any math topic (Shoutout to Jon!). Just say \"I have a math problem\" and 10 heads will snap in your direction. Problem sets are\ngraded daily by the counsellors. Being in a 4-person \"family\" with a consellor creates a sense\nof camaraderie, which is good because I arrived at Ross not knowing anyone.\n\n\n## Lectures\nSpecial lectures are given by the counsellors and professors from [OSU](https://www.osu.edu/). These are\nvery exciting and you do not want to miss them. They cover eclectic topics ranging from modular forms\nto computation theory. I made the mistake of missing out on Vitaly Berglesson's Pigeonhole lecture series in\nthe first week and I regret that I did not go. The lectures introduce you to new subjects and really broadened\nmy conception of what I thought math encompassed. My favourite talk might have been Oscar's talk on the [hyper-reals](https://en.wikipedia.org/wiki/Hyperreal_number)\n\n## The Community\nThe community was my favorite thing about Ross. It is one thing to solve interesting problems, but it\nis quite another to collaborate on problems with people who are just as obsessed with math. \nWe all sort of egged each other on to solve more problems and inspired each other. I feel\nthat the biggest advantage of the Ross Program is that **it prepares you for how life will be in\nuniversity**. I.E. in university, you will likely specialize in a subject and hang out with people\nin a similar major to discuss your shared passion. \n\n## The Food\nI'd rather not dwell on this subject for too long.\n\n\n## Tips\nIf you are going to the Ross Program, I have some tips for you.\n- learn how to use a washing machine before you go\n- bring some emergency food with you\n- **pro tip:** bring a sleeping bag because the dorm beds are unsatisfactory to say the least. If you bring \na sleeping bag, you will be able to sleep.\n- In a similar vein, bring ear-plugs, because there are some people in the next dorm over\nwho say up very late and you don't want to be kept awake\n- The Ross website may claim that you shouldn't bring phones/computers/board games/cards, but \nyou will probably be fine if you bring these things.\n\n\n## Should you go to Ross?\nIf you would like to do math for 10 hours a day, for 7 days a week, for 6 weeks straight, then apply \nto the Ross Program. I was a bit intimidated at first because I had never done that much math\nbefore, but I really liked the experience. ","date":"August 28, 2022","tags":["math"," math program"," Ross"," Ross program"],"title":"A Review of the Ross Program","slug":"ross","description":"I just attended the Ross Program","image":"/images/ross-logo.svg"},{"content":"\nSandeep Srinivasan is a veteran of the machine learning industry. While most have gravitated towards it since the hype of the late 2000s, Srinivasan claims he has been “interested in machine learning since the 1990s,” almost noachian in this quickly evolving field. Today, I sat down with Srinivasan in order to glean what insights he has after pioneering this industry for 30 years. \n\nI am struck by Srinivasan’s positive attitude. He himself concurs, saying its necessary to be “a lifelong learner” to succeed in this field. Even with his experience, he is “still taking courses” to learn new skills and improve himself. His optimism extends further, however. When describing how he first got into machine learning, Srinivasan said a professor was too embarrassed that no one signed up for his course in machine learning, so he paid Srinivasan $10 an hour to be the only attendant. Despite being happenstance, Srinivasan tells the story with a smile as if it is a good joke. He brings this sense of optimism to his work, summarizing that the “best part of [his] job” is to meet bright 20-year-olds who have a “beginner’s mindset” and are eager to learn. \n\nFinding these bright 20-year-olds is becoming increasingly difficult for Srinivasan, unfortunately. In this white-hot field, he must muscle his way through the likes of “Google, Facebook, Amazon, and Apple.” Due to this drive for talent, Srinivasan complains that “the hardest part” of his job is hiring for his small machine learning startup.\n\nDespite his recruiting woes, Srinivasan claims he is not deterred about founding a small machine learning startup. He says the experience has been rewarding for him. When speaking on the advantages of founding a startup, he says he gets to “eat [his] own dog food,” in the sense that he is excited to try out all the products as a consumer that he is inventing. He emphasize that a founder must act as the first customer of a product, because if the founder doesn’t believe in the product, then neither will the clients. \n\nThe main area where Srinivasan eagerly gets to try out his new inventions is with his products aiming to “simplify machine learning.” He uses his own online dashboard to set up machine learning models in a few clicks, and soon he hopes others can do the same. His mission is to “democratize machine learning for multiple applications.”  In the future, Srinivasan imagines that doctors or other domain experts could create machine learning models without coding and without technical knowledge. \n\t\nDoctors are not the only profession Srinivasan predicts machine learning will impact. He thinks that many “repetitive tasks” such as “data entry” for taxes will disappear. In addition, manual tasks, such as image labeling will be automated away by machine learning.\n\nOverall, I am very impressed with Srinivasan’s accomplishments. He certainly has the air of someone well-informed on the industry, and he was able to use his knowledge to give me personal advice for the job market (“learn statistics”). Given how he effuses knowledge in every aspect of machine learning, I would not be surprised if his startup goes far. This experience was very informative for me, and I see myself possibly having a career in machine learning. I suggest to the reader to conduct a similar informational interview, in the hopes that one could learn about an intriguing field from a personality. \n\n\n \n","date":"Feb 27, 2022","tags":["machine learning"," interview"," coding"],"title":"Interview with Machine Learning Expert","slug":"sandeep-interview","description":"After his 30 years in the field, machine learning engineer Sandeep Srinivasan offers advice on how to tackle this complex career.","image":"/images/sandeep.jpg"}]},"__N_SSG":true}